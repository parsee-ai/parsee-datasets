{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffb7f49-f546-4095-9223-37729b825949",
   "metadata": {},
   "source": [
    "# finRAG Study Results\n",
    "By Thomas Flassbeck ([twitter](https://twitter.com/flashback_t) | [linkedin](https://www.linkedin.com/in/thomas-flassbeck-90aa72104/)) from Parsee.ai.\n",
    "\n",
    "Last update on May 15th, 2024, with the GPT-4 Omni results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d461d3b8-8bd9-4b40-b5c4-12b5684c999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from run_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98ae6bb-5252-46a7-b1fe-a44a5089d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL settings for this run (v2)\n",
    "token_limit = 8000\n",
    "# Parsee.ai template ID, can be seen here (requires free log-in): https://app.parsee.ai/template/662a37cb080aaf6db5499923\n",
    "template_id = \"662a37cb080aaf6db5499923\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c69b3d-2c84-4f13-9a1e-73d576c5fa1c",
   "metadata": {},
   "source": [
    "# RAG-text Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b3eec-42dc-4099-80d7-40bdc005244c",
   "metadata": {},
   "source": [
    "Note: Snowflake arctic is excluded from the RAG-text datasets as it was not able to return results consistently even at a reduced context length of 3.5k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722f8320-7e21-4603-99e0-73a3af4b453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following models are being used:\n",
    "models = [\n",
    "            anthropic_config(\"n/a\", \"claude-3-opus-20240229\", token_limit),\n",
    "            gpt_config(\"n/a\", token_limit, \"gpt-4-1106-preview\"),\n",
    "            gpt_config(\"n/a\", token_limit, \"gpt-4o\"),\n",
    "            replicate_config(\"n/a\", \"meta/meta-llama-3-70b-instruct\", token_limit),\n",
    "            together_config(\"n/a\", \"mistralai/Mixtral-8x22B-Instruct-v0.1\", token_limit),\n",
    "            mistral_api_config(None, \"mistral-large-latest\", token_limit),\n",
    "            together_config(\"n/a\", \"databricks/dbrx-instruct\", token_limit),\n",
    "            cohere_config(\"n/a\", \"command-r-plus\", token_limit),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478ef3bf-dc23-4cc9-adb3-a05d3242ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>total</th>\n",
       "      <th>rag_text_100_rev_meta_total</th>\n",
       "      <th>rag_text_100_rev23_meta_total</th>\n",
       "      <th>rag_text_100_rev22_meta_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.953037</td>\n",
       "      <td>0.896610</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.9775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>0.871469</td>\n",
       "      <td>0.914407</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.7225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0.827754</td>\n",
       "      <td>0.595763</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mistral-large-latest</td>\n",
       "      <td>0.765508</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>command-r-plus</td>\n",
       "      <td>0.669364</td>\n",
       "      <td>0.435593</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta/meta-llama-3-70b-instruct</td>\n",
       "      <td>0.516568</td>\n",
       "      <td>0.132203</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistralai/Mixtral-8x22B-Instruct-v0.1</td>\n",
       "      <td>0.469195</td>\n",
       "      <td>0.255085</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>databricks/dbrx-instruct</td>\n",
       "      <td>0.247175</td>\n",
       "      <td>0.191525</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.2350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model     total  \\\n",
       "2                                 gpt-4o  0.953037   \n",
       "0                 claude-3-opus-20240229  0.871469   \n",
       "1                     gpt-4-1106-preview  0.827754   \n",
       "5                   mistral-large-latest  0.765508   \n",
       "7                         command-r-plus  0.669364   \n",
       "3         meta/meta-llama-3-70b-instruct  0.516568   \n",
       "4  mistralai/Mixtral-8x22B-Instruct-v0.1  0.469195   \n",
       "6               databricks/dbrx-instruct  0.247175   \n",
       "\n",
       "   rag_text_100_rev_meta_total  rag_text_100_rev23_meta_total  \\\n",
       "2                     0.896610                         0.9850   \n",
       "0                     0.914407                         0.9775   \n",
       "1                     0.595763                         0.9625   \n",
       "5                     0.491525                         0.9550   \n",
       "7                     0.435593                         0.9025   \n",
       "3                     0.132203                         0.6575   \n",
       "4                     0.255085                         0.5900   \n",
       "6                     0.191525                         0.3150   \n",
       "\n",
       "   rag_text_100_rev22_meta_total  \n",
       "2                         0.9775  \n",
       "0                         0.7225  \n",
       "1                         0.9250  \n",
       "5                         0.8500  \n",
       "7                         0.6700  \n",
       "3                         0.7600  \n",
       "4                         0.5625  \n",
       "6                         0.2350  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, all_dataset_names = make_df(template_id, \"../data/v2/answers_150524/rag-text\", models)\n",
    "df[['model', 'total']+[f\"{x}_total\" for x in all_dataset_names]].sort_values('total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbc5f0-ab0a-4de2-b85e-25fe076c6116",
   "metadata": {},
   "source": [
    "# Selection-text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45072506-d091-4a7b-931c-55fe49af0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token limit is still set to 8k for all models, except for the Snowflake Arctic model, which has a max. context of 4k tokens (we set the context to 3k here as it was throwing many errors at 4k context before).\n",
    "# The token limit is not really relevant for this dataset as all the prompts contain at most ~3k tokens.\n",
    "# The following models are being used:\n",
    "models = [\n",
    "            anthropic_config(\"n/a\", \"claude-3-opus-20240229\", token_limit),\n",
    "            gpt_config(\"n/a\", token_limit, \"gpt-4-1106-preview\"),\n",
    "            gpt_config(\"n/a\", token_limit, \"gpt-4o\"),\n",
    "            replicate_config(\"n/a\", \"meta/meta-llama-3-70b-instruct\", token_limit),\n",
    "            together_config(\"n/a\", \"mistralai/Mixtral-8x22B-Instruct-v0.1\", token_limit),\n",
    "            mistral_api_config(None, \"mistral-large-latest\", token_limit),\n",
    "            together_config(\"n/a\", \"databricks/dbrx-instruct\", token_limit),\n",
    "            cohere_config(\"n/a\", \"command-r-plus\", token_limit),\n",
    "            together_config(\"n/a\", \"Snowflake/snowflake-arctic-instruct\", 3000)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9ff604-1029-46ef-b1c4-ec52a0f50f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>total</th>\n",
       "      <th>selection_text_100_rev23_meta_total</th>\n",
       "      <th>selection_text_100_rev_meta_total</th>\n",
       "      <th>selection_text_100_rev22_meta_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.995523</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.994068</td>\n",
       "      <td>0.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>0.973023</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.994068</td>\n",
       "      <td>0.9325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral-large-latest</td>\n",
       "      <td>0.971554</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.979661</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0.968573</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.943220</td>\n",
       "      <td>0.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta/meta-llama-3-70b-instruct</td>\n",
       "      <td>0.838192</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.674576</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>command-r-plus</td>\n",
       "      <td>0.746073</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.493220</td>\n",
       "      <td>0.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistralai/Mixtral-8x22B-Instruct-v0.1</td>\n",
       "      <td>0.687288</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.661864</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>databricks/dbrx-instruct</td>\n",
       "      <td>0.530890</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.410169</td>\n",
       "      <td>0.6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Snowflake/snowflake-arctic-instruct</td>\n",
       "      <td>0.280862</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.155085</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model     total  \\\n",
       "2                                 gpt-4o  0.995523   \n",
       "0                 claude-3-opus-20240229  0.973023   \n",
       "4                   mistral-large-latest  0.971554   \n",
       "1                     gpt-4-1106-preview  0.968573   \n",
       "8         meta/meta-llama-3-70b-instruct  0.838192   \n",
       "6                         command-r-plus  0.746073   \n",
       "3  mistralai/Mixtral-8x22B-Instruct-v0.1  0.687288   \n",
       "5               databricks/dbrx-instruct  0.530890   \n",
       "7    Snowflake/snowflake-arctic-instruct  0.280862   \n",
       "\n",
       "   selection_text_100_rev23_meta_total  selection_text_100_rev_meta_total  \\\n",
       "2                               1.0000                           0.994068   \n",
       "0                               0.9925                           0.994068   \n",
       "4                               0.9775                           0.979661   \n",
       "1                               0.9700                           0.943220   \n",
       "8                               0.9000                           0.674576   \n",
       "6                               0.8875                           0.493220   \n",
       "3                               0.7500                           0.661864   \n",
       "5                               0.5775                           0.410169   \n",
       "7                               0.3475                           0.155085   \n",
       "\n",
       "   selection_text_100_rev22_meta_total  \n",
       "2                               0.9925  \n",
       "0                               0.9325  \n",
       "4                               0.9575  \n",
       "1                               0.9925  \n",
       "8                               0.9400  \n",
       "6                               0.8575  \n",
       "3                               0.6500  \n",
       "5                               0.6050  \n",
       "7                               0.3400  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, all_dataset_names = make_df(template_id, \"../data/v2/answers_150524/selection-text\", models)\n",
    "df[['model', 'total']+[f\"{x}_total\" for x in all_dataset_names]].sort_values('total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a114d-ba58-4602-a237-ba263e6a7fa9",
   "metadata": {},
   "source": [
    "# Selection-image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffac346d-aec3-48ae-8dd7-a6150d0c11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token limit is still set to 8k for all models\n",
    "# The token limit is not really relevant for this dataset as all the prompts contain at most ~1k tokens.\n",
    "# The following models are being used:\n",
    "models = [\n",
    "            anthropic_config(\"n/a\", \"claude-3-opus-20240229\", token_limit, True, 1),\n",
    "            gpt_config(\"n/a\", token_limit, \"gpt-4o\"),\n",
    "            gpt_config(\"n/a\", token_limit, \"gpt-4-1106-vision-preview\", True, 1),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9786973a-40ca-48c1-83e5-ce6b5f9b5cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>total</th>\n",
       "      <th>selection_image_100_rev23_meta_total</th>\n",
       "      <th>selection_image_100_rev22_meta_total</th>\n",
       "      <th>selection_image_100_rev_meta.csv_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.952528</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.955085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>0.610395</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.771186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-1106-vision-preview</td>\n",
       "      <td>0.581398</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.501695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model     total  selection_image_100_rev23_meta_total  \\\n",
       "1                     gpt-4o  0.952528                                0.9625   \n",
       "0     claude-3-opus-20240229  0.610395                                0.6975   \n",
       "2  gpt-4-1106-vision-preview  0.581398                                0.7975   \n",
       "\n",
       "   selection_image_100_rev22_meta_total  \\\n",
       "1                                0.9400   \n",
       "0                                0.3625   \n",
       "2                                0.4450   \n",
       "\n",
       "   selection_image_100_rev_meta.csv_total  \n",
       "1                                0.955085  \n",
       "0                                0.771186  \n",
       "2                                0.501695  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, all_dataset_names = make_df(template_id, \"../data/v2/answers_150524/selection-image\", models)\n",
    "df[['model', 'total']+[f\"{x}_total\" for x in all_dataset_names]].sort_values('total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e7acf-73a9-47cc-b895-2b15a739f4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
